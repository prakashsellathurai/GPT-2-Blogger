{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2-Blogger",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMerWm9EwHSa33EflUdgIAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashsellathurai/GPT-2-Blogger/blob/main/GPT_2_Blogger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0mrN1ltr7h9",
        "outputId": "1171faf1-89a4-4b64-c886-97bfbe4b0788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 21 15:41:31 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    74W / 149W |     69MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbKpa_TcrJMo"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqBtJh8Ht6m1",
        "outputId": "9b3d6ae1-8423-4699-9208-db7fa1efea9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 166Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 75.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 385Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:48, 29.2Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 168Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 64.9Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 102Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT0ET563uFUi",
        "outputId": "ef39cf83-13c4-4714-aaed-a33ede569e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBPAMLbFuO3n",
        "outputId": "9bee307b-3546-4e63-84dd-c796101981b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "!wget https://www.gwern.net/docs/ai/poetry/2019-03-06-gpt2-poetry-1000samples.txt"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-21 15:43:56--  https://www.gwern.net/docs/ai/poetry/2019-03-06-gpt2-poetry-1000samples.txt\n",
            "Resolving www.gwern.net (www.gwern.net)... 104.26.7.107, 104.26.6.107, 172.67.72.106, ...\n",
            "Connecting to www.gwern.net (www.gwern.net)|104.26.7.107|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3673274 (3.5M) [text/plain]\n",
            "Saving to: ‘2019-03-06-gpt2-poetry-1000samples.txt’\n",
            "\n",
            "\r          2019-03-0   0%[                    ]       0  --.-KB/s               \r2019-03-06-gpt2-poe 100%[===================>]   3.50M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-10-21 15:43:56 (80.9 MB/s) - ‘2019-03-06-gpt2-poetry-1000samples.txt’ saved [3673274/3673274]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC2my0YO0MjF"
      },
      "source": [
        "file_name = \"2019-03-06-gpt2-poetry-1000samples.txt\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffahhSUXzKBe",
        "outputId": "ffde43dd-0cc4-4c78-f8ac-6d92ed3e843f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=5000,\n",
        "              restore_from='latest',\n",
        "              run_name='run42K',\n",
        "              print_every=10,\n",
        "              sample_every=5000,\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1034166 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL4hW5yNyRzs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}