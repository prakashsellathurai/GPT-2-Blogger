{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference-gpt-2-blogger-colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTO4mFvVpqEDASAEMZTIdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashsellathurai/GPT-2-Blogger/blob/main/inference_gpt_2_blogger_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx8xeL9iHCYd",
        "outputId": "7e205ed7-6587-411d-e946-13eeaffe6f08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Rq8VfGHfxE",
        "outputId": "baa6dd24-330b-4df0-a094-a8ad4130d19d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDFxx-8CHkIZ"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run42K')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8gFOC2YHnP8",
        "outputId": "ddb70239-e5f3-40d0-b1b8-df4be59151db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run42K')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run42K/model-5000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run42K/model-5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU2CRFSLHr9r",
        "outputId": "57292a7f-d00b-413f-fae1-2b1feefae661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpt2.generate(sess, run_name='run42K',\n",
        "             length=100,\n",
        "             prefix=\"<|startoftext|>\",\n",
        "             truncate=\"<|endoftext|>\",\n",
        "             include_prefix=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<|startoftext|>_I_ am _pagan_. I am _dear_ to all, dear _Mephistopheles_! I love _you_! And if the love of you is too dear to me, dear _Mephistopheles_! I _will_ give you,--as many kisses as you would give,--and so,--for the rest, you are to kiss me,--_made in_ the _pallet_.\n",
            "But I am _del\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBTRQNkgJW0W"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      run_name='run42K',\n",
        "                      destination_path=gen_file,\n",
        "                      length=100,\n",
        "                      temperature=1.0,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20,\n",
        "                      prefix=\"<|startoftext|>\",\n",
        "                      truncate=\"<|endoftext|>\",\n",
        "                      include_prefix=False,\n",
        "                      sample_delim=''\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}